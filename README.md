# Vision and Text To Language (ViTToL) Model and its Application to MIMIC Dataset	

## Aswin Thiruvengadam, Dicky Woo, Kai Ying

### 2023 Summer 210-009 Capstone

### Abstract

According to a study conducted by Andreas Otto Josef Zabel et al., the turnover time for medical radiologist reporting at major hospitals takes on average 245 to 288 minutes.  This process is lengthy and costly. Our research intends to provide a supplementary solution to the problem by providing automatic x-ray annotation and reporting using a vision-language model. This research focuses on the annotation of chest x-rays using MIMIC data with a vision language model with an adapter architecture. The model takes x-ray images as inputs and outputs a short descriptive narrative of findings to assist radiologists in making diagnosis and reporting more efficient, effective and less burdensome. As an extension of the application of the model, we also develop an auto-completion tool as an assistive tool for radiologist to write x-ray reports effectively and efficiently.

### Introduction

X-ray annotation is costly. Radiologists in the U.S. perform on average over 70 million chest x-rays each year.  Furthermore, the cost for imaging and professional reading/interpretation is between $150 and $1,200.  While being expensive, according to a study conducted by Andreas Otto Josef Zabel et al., the turnover time for medical radiologist reporting at major hospitals takes on average 245 to 288 minutes.  However, increasing the speed radiologist reading is shown to have a significant impact on the accuracy of the report without tooling improvement. Evgeniya Sokolovskaya et al. has found that the error rate of major misses increased was 26% among the radiologists reporting at a faster speed, compared with 10% at normal speed in their study on reporting speed.  In the following section, we outline the research of a Vision and Text To Language (ViTToL) model that is shown to have a state-of-the-art performance in classification of diseases at par to a radiologist. However, due to the importance of eliminating any false negative and false positive, we intend this model to be an assistive tool that could help radiologists accurately annotate x-rays with increased reporting speed while either maintaining or improving reporting accuracy.

### Data & Methods

#### Data
![MIMIC Data Structure](https://github.com/k378/k378.github.io/blob/main/data_structure.png "MIMIC Data Structure")

#### Baseline Model

#### ViTToL Model				

### Results					

#### Baseline Model

#### ViTToL Model							

### Experiment 			

### Future Work			

### Conclusion				

### Reference					
[1] 				
[2]						
[3]					
[4] 				
[5]	
[6] 	

